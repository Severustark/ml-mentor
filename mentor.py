# mentor.py
# ğŸ“ ML Mentor AsistanÄ± (PDF + FAISS + 5+ konu asistanÄ±)
# Ã‡alÄ±ÅŸtÄ±rma:
#   1) .env dosyasÄ±na OPENAI_API_KEY ve ML_PDF_PATH yaz
#   2) python mentor.py
# Ã‡Ä±kÄ±ÅŸ: 'Ã§Ä±k' / 'exit' / 'quit'

import os
import re
from dataclasses import dataclass
from typing import List, Dict, Tuple

from dotenv import load_dotenv

# --------- Ortam ---------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
PDF_PATH       = os.getenv("ML_PDF_PATH", "data/pdfs/ml_intro.pdf").strip()
TOP_K          = int(os.getenv("TOP_K", "4"))
SIM_THRESHOLD  = float(os.getenv("SIM_THRESHOLD", "0.30"))
USE_LLM        = os.getenv("USE_LLM", "1") == "1"

if not OPENAI_API_KEY:
    raise SystemExit("OPENAI_API_KEY eksik. LÃ¼tfen .env dosyasÄ±na ekleyin.")

# --------- LangChain ---------
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document

# --------- Tohum Bilgiler (docs) ---------
SEED_DOCS: List[str] = [
    "Makine Ã–ÄŸrenmesi: BilgisayarlarÄ±n veriden Ã¶ÄŸrenerek, aÃ§Ä±kÃ§a programlanmadan tahmin veya karar vermesini saÄŸlayan yapay zeka dalÄ±dÄ±r.",
    "Denetimli Ã–ÄŸrenme: Girdi ve Ã§Ä±ktÄ± Ã¶rnekleri ile eÄŸitilen, sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde kullanÄ±lan yÃ¶ntemdir.",
    "Denetimsiz Ã–ÄŸrenme: Ã‡Ä±kÄ±ÅŸ etiketleri olmadan, verideki gizli yapÄ±larÄ± keÅŸfetmeye Ã§alÄ±ÅŸan yÃ¶ntemdir (Ã¶rneÄŸin kÃ¼meleme).",
    "YarÄ± Denetimli Ã–ÄŸrenme: KÃ¼Ã§Ã¼k bir etiketli veri ve bÃ¼yÃ¼k miktarda etiketsiz veri kullanÄ±larak eÄŸitilen yÃ¶ntemdir.",
    "PekiÅŸtirmeli Ã–ÄŸrenme: AjanÄ±n Ã§evresiyle etkileÅŸime girip Ã¶dÃ¼l/ceza mekanizmasÄ±yla Ã¶ÄŸrenmesini saÄŸlayan yÃ¶ntemdir.",
    "EÄŸitim/Test AyrÄ±mÄ±: EÄŸitim seti Ã¶ÄŸrenme iÃ§in, test seti genelleme baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r.",
    "Overfitting: Modelin eÄŸitim verisine aÅŸÄ±rÄ± uyum saÄŸlamasÄ± ve genelleme yeteneÄŸinin dÃ¼ÅŸmesidir.",
    "Underfitting: Modelin yeterince Ã¶ÄŸrenememesi; hem eÄŸitim hem testte dÃ¼ÅŸÃ¼k baÅŸarÄ±.",
    "Bias-Variance Dengesi: DÃ¼ÅŸÃ¼k bias ve dÃ¼ÅŸÃ¼k varyans arasÄ±ndaki denge modelin baÅŸarÄ±sÄ± iÃ§in kritiktir.",
    "Cross Validation: Veriyi katmanlara ayÄ±rarak modelin farklÄ± parÃ§alarda test edilmesini saÄŸlar.",
    "Feature Engineering: Ã–zellik oluÅŸturma/dÃ¶nÃ¼ÅŸtÃ¼rme ile model performansÄ±nÄ± artÄ±rma sÃ¼reci.",
    "Gradient Descent: KayÄ±p fonksiyonunu minimize etmek iÃ§in kullanÄ±lan optimizasyon algoritmasÄ±.",
    "Karar AÄŸaÃ§larÄ±: SÄ±nÄ±flandÄ±rma ve regresyonda dallanma kurallarÄ± ile karar veren modeller.",
    "k-NN: KomÅŸuluk iliÅŸkisine dayalÄ± sÄ±nÄ±flandÄ±rma/regresyon algoritmasÄ±.",
    "SVM: Veriyi ayÄ±ran en uygun hiperdÃ¼zlemi arayan gÃ¼Ã§lÃ¼ sÄ±nÄ±flandÄ±rma algoritmasÄ±.",
    "DeÄŸerlendirme Metrikleri: Accuracy, Precision, Recall, F1, ROC, AUC vb.",
    "Boyut Azaltma: YÃ¼ksek boyutlu veride PCA gibi yÃ¶ntemlerle daha dÃ¼ÅŸÃ¼k boyutlu temsil.",
    "Uygulamalar: GÃ¶rÃ¼ntÃ¼ iÅŸleme, NLP, Ã¶neri sistemleri, saÄŸlÄ±k, finans vb."
]

# --------- PDF yÃ¼kleme ve parÃ§alama ---------
def load_pdf_chunks(pdf_path: str) -> List[Document]:
    if not os.path.exists(pdf_path):
        print(f"âš ï¸ PDF bulunamadÄ±: {pdf_path}. Sadece tohum metinlerle devam edilecek.")
        return []
    loader = PyPDFLoader(pdf_path)
    raw_docs = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=150)
    chunks = splitter.split_documents(raw_docs)

    # Basit bÃ¶lÃ¼m etiketleme (heuristic)
    for c in chunks:
        c.metadata = c.metadata or {}
        c.metadata["source"] = os.path.basename(pdf_path)
        t = c.page_content.lower()
        if any(k in t for k in ["giriÅŸ", "nedir", "tanÄ±m"]):
            c.metadata["section"] = "temeller"
        elif any(k in t for k in ["Ã¶ÄŸrenme tÃ¼r", "denetimli", "denetimsiz", "takviyeli"]):
            c.metadata["section"] = "turler"
        elif any(k in t for k in ["Ã¶zellik", "feature", "veri hazÄ±rlama", "Ã¶n iÅŸleme"]):
            c.metadata["section"] = "veri"
        elif any(k in t for k in ["algoritma", "model", "sÄ±nÄ±flandÄ±rma", "regresyon"]):
            c.metadata["section"] = "modelleme"
        elif any(k in t for k in ["metrik", "performans", "doÄŸruluk", "precision", "recall", "f1", "roc", "auc", "Ã§apraz doÄŸrulama"]):
            c.metadata["section"] = "degerlendirme"
        elif any(k in t for k in ["optimizasyon", "hiperparametre", "grid", "bayesian"]):
            c.metadata["section"] = "optimizasyon"
        else:
            c.metadata["section"] = "diger"
    return chunks

# --------- VektÃ¶r veritabanÄ± (FAISS) ---------
def build_faiss(seed_texts: List[str], pdf_chunks: List[Document]) -> FAISS:
    seed_docs = [Document(page_content=t, metadata={"source": "seed", "section": "temeller"}) for t in seed_texts]
    all_docs = seed_docs + pdf_chunks
    if not all_docs:
        raise RuntimeError("HiÃ§ belge yok: PDF bulunamadÄ± ve seed de boÅŸ!")
    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
    db = FAISS.from_documents(all_docs, embeddings)
    return db

# --------- Asistan yapÄ±sÄ± ---------
@dataclass
class Assistant:
    name: str
    section_keys: List[str]
    keywords: List[str]

def make_assistants() -> Dict[str, Assistant]:
    return {
        "temeller":      Assistant("Temeller", ["temeller"], ["nedir", "giriÅŸ", "tanÄ±m", "ai", "ml", "dl", "temel"]),
        "turler":        Assistant("Ã–ÄŸrenme TÃ¼rleri", ["turler"], ["denetimli", "denetimsiz", "takviyeli", "yarÄ±", "reinforcement"]),
        "veri":          Assistant("Veri & Ã–zellik MÃ¼hendisliÄŸi", ["veri"], ["Ã¶zellik", "feature", "Ã¶n iÅŸleme", "temizleme", "normalizasyon"]),
        "modelleme":     Assistant("Modelleme", ["modelleme"], ["algoritma", "sÄ±nÄ±flandÄ±rma", "regresyon", "svm", "knn", "aÄŸaÃ§"]),
        "degerlendirme": Assistant("DeÄŸerlendirme & Metrikler", ["degerlendirme"], ["doÄŸruluk", "precision", "recall", "f1", "roc", "auc", "cross validation"]),
        "optimizasyon":  Assistant("Optimizasyon", ["optimizasyon"], ["hiperparametre", "grid", "bayesian", "optimizasyon"]),
        "diger":         Assistant("DiÄŸer", ["diger"], []),
    }

def select_assistant(query: str, assistants: Dict[str, Assistant]) -> Assistant:
    q = query.lower()
    best_key, best_score = "temeller", 0
    for key, a in assistants.items():
        score = sum(1 for kw in a.keywords if kw in q)
        if score > best_score:
            best_key, best_score = key, score
    return assistants[best_key]

# --------- Benzerlik skoru (heuristic) ---------
def relevance_score(query: str, text: str) -> float:
    q_terms = [w for w in re.findall(r"\w+", query.lower()) if len(w) > 2]
    toks = [w for w in re.findall(r"\w+", text.lower()) if len(w) > 2]
    if not toks:
        return 0.0
    hits = sum(1 for t in q_terms if t in toks)
    return hits / (len(set(toks)) ** 0.5)

# --------- YanÄ±t Ã¼retici (invoke ile) ---------
def answer_query(db: FAISS, query: str, assistant: Assistant) -> Tuple[str, float]:
    # FAISS retriever
    retriever = db.as_retriever(search_kwargs={"k": TOP_K})

    # Yeni API: get_relevant_documents yerine invoke
    candidates = retriever.invoke(query)  # -> List[Document]
    if not candidates:
        return "", 0.0

    # AsistanÄ±n section'Ä±na filtre uygula (yoksa tÃ¼mÃ¼)
    filtered = [d for d in candidates if d.metadata.get("section") in assistant.section_keys] or candidates

    # En alakalÄ±yÄ± seÃ§ ve basit eÅŸik uygula
    best = max(filtered, key=lambda d: relevance_score(query, d.page_content))
    score = relevance_score(query, best.page_content)
    if score < SIM_THRESHOLD:
        return "", score

    # BaÄŸlamÄ± oluÅŸtur
    context = "\n\n".join(d.page_content for d in filtered)

    # LLM kullanmadan sadece pasaj dÃ¶ndÃ¼rmek istersen:
    if not USE_LLM:
        snippet = best.page_content.strip()
        return (snippet[:800] + ("..." if len(snippet) > 800 else "")), score

    # LLM ile, SADECE baÄŸlama dayanarak yanÄ±t
    llm = ChatOpenAI(api_key=OPENAI_API_KEY, model="gpt-4o-mini", temperature=0)
    system = (
        "Sen bir makine Ã¶ÄŸrenimi mentÃ¶rÃ¼sÃ¼n. SADECE verilen baÄŸlamdan yararlan. "
        "BaÄŸlamda olmayan bilgi uydurma; emin deÄŸilsen 'belgede yok' de. "
        "KÄ±sa ve Ã¶z anlat."
    )
    prompt = f"{system}\n\n[BAÄLAM]\n{context}\n\n[SORU]\n{query}\n\n[CEVAP]"
    out = llm.invoke(prompt).content
    return out, score

# --------- main ---------
def main():
    pdf_chunks = load_pdf_chunks(PDF_PATH)
    db = build_faiss(SEED_DOCS, pdf_chunks)
    assistants = make_assistants()

    print("ğŸ“ ML Mentor AsistanÄ± hazÄ±r. ('Ã§Ä±k' / 'exit' / 'quit' ile Ã§Ä±kÄ±ÅŸ)")
    print(f"ğŸ“„ PDF: {PDF_PATH if os.path.exists(PDF_PATH) else 'YOK (sadece seed)'}")
    print(f"ğŸ” EÅŸik: {SIM_THRESHOLD} | TOP_K: {TOP_K}\n")

    while True:
        try:
            q = input("ğŸ‘¤ Siz: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nGÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break

        if q.lower() in ["Ã§Ä±k", "exit", "quit"]:
            print("GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break

        a = select_assistant(q, assistants)
        ans, sc = answer_query(db, q, a)

        if not ans:
            print(f"ğŸ¤– {a.name}: ÃœzgÃ¼nÃ¼m, belgelerde bu soruya dair yeterli bilgi bulamadÄ±m. (skor={sc:.2f})\n")
        else:
            print(f"ğŸ¤– {a.name}: {ans}\n   (skor={sc:.2f})\n")

if __name__ == "__main__":
    main()
